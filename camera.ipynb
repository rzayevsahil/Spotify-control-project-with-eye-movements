{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Access to the camera was successfully obtained\n",
      "\n",
      "\n",
      "\n",
      "Streaming started - to quit press ESC\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "\n",
      "\n",
      "\n",
      "Streaming ended\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from pynput.keyboard import Key,Controller\n",
    "keyboard = Controller()\n",
    "import time\n",
    "\n",
    "def get_extended_image(img, x, y, w, h, k=0.1):\n",
    "    # The next code block checks that coordinates will be non-negative\n",
    "    # (in case if desired image is located in top left corner)\n",
    "    if x - k*w > 0:\n",
    "        start_x = int(x - k*w)\n",
    "    else:\n",
    "        start_x = x\n",
    "    if y - k*h > 0:\n",
    "        start_y = int(y - k*h)\n",
    "    else:\n",
    "        start_y = y\n",
    "\n",
    "    end_x = int(x + (1 + k)*w)\n",
    "    end_y = int(y + (1 + k)*h)\n",
    "\n",
    "    face_image = img[start_y:end_y,\n",
    "                     start_x:end_x]\n",
    "    face_image = tf.image.resize(face_image, [224, 224])\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    return face_image\n",
    "\n",
    "video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # webcamera\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"\\n\\n\\nUnable to access the camera\")\n",
    "else:\n",
    "    print(\"\\n\\n\\nAccess to the camera was successfully obtained\")\n",
    "\n",
    "print(\"\\n\\n\\nStreaming started - to quit press ESC\")\n",
    "\n",
    "face_classifier = keras.models.load_model('D:/projects/proje/modeller/Model3.h5')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "class_names = ['Gozler Kapali', 'Sol Goz Kapali','Gozler Acik','Sag Goz Kapali']\n",
    "kapali=class_names[0]\n",
    "sol=class_names[1]\n",
    "acik=class_names[2]\n",
    "sag=class_names[3]\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"\\n\\n\\nCan't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # for each face on the image detected by OpenCV\n",
    "        # get extended image of this face\n",
    "        face_image = get_extended_image(frame, x, y, w, h, 0.5)\n",
    "\n",
    "        # classify face and draw a rectangle around the face\n",
    "        # green for positive class and red for negative\n",
    "        result = face_classifier.predict(face_image)\n",
    "        prediction = class_names[np.array(\n",
    "            result[0]).argmax(axis=0)]  # predicted class\n",
    "        confidence = np.array(result[0]).max(axis=0)  # degree of confidence\n",
    "\n",
    "        if prediction == kapali:\n",
    "            color = (0,0,255)  #red\n",
    "            keyboard.press(key=Key.media_play_pause)\n",
    "            time.sleep(0.5)\n",
    "            keyboard.release(key=Key.media_play_pause)\n",
    "            time.sleep(1.5)\n",
    "        elif prediction == sol:\n",
    "            color = (255,0,0) #blue\n",
    "            keyboard.press(key=Key.media_previous)\n",
    "            time.sleep(0.5)\n",
    "            keyboard.release(key=Key.media_previous)\n",
    "            time.sleep(1.5)\n",
    "        elif prediction == acik:\n",
    "            color = (255,255,255)\n",
    "        elif prediction == sag:\n",
    "            color = (0,255,0)\n",
    "            keyboard.press(key=Key.media_next)\n",
    "            time.sleep(1)\n",
    "            keyboard.release(key=Key.media_next)\n",
    "            print('i')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame,\n",
    "                      (x, y),  # start_point\n",
    "                      (x+w, y+h),  # end_point\n",
    "                      color,\n",
    "                      2)  # thickness in px\n",
    "        cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    2,  # fontScale\n",
    "                    color,\n",
    "                    2)  # thickness in px\n",
    "\n",
    "    # display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "\n",
    "\n",
    "# when everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"\\n\\n\\nStreaming ended\")\n",
    "\n",
    "# Load model to face classification\n",
    "# model was created in me_not_me_classifier.ipynb notebook\n",
    "model_name = 'face_classifier_MobileNet_15.h5'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
